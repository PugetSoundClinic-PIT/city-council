{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Whole Comment Seg Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to create a copy of the transcripts in this directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evamaxfield/micromamba/envs/city-council/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching each model attached to event_ref: 100%|██████████| 640/640 [00:04<00:00, 141.84it/s]\n",
      "Fetching transcripts: 100%|██████████| 640/640 [00:06<00:00, 96.67it/s] \n",
      "Converting transcripts: 100%|██████████| 640/640 [00:01<00:00, 418.76it/s]\n",
      "Fetching each model attached to event_ref: 100%|██████████| 308/308 [00:03<00:00, 92.54it/s] \n",
      "Fetching transcripts: 100%|██████████| 308/308 [00:03<00:00, 79.63it/s]\n",
      "Converting transcripts: 100%|██████████| 307/307 [00:01<00:00, 174.19it/s]\n",
      "Fetching each model attached to event_ref: 100%|██████████| 544/544 [00:04<00:00, 121.61it/s]\n",
      "Fetching transcripts: 100%|██████████| 544/544 [00:06<00:00, 89.84it/s] \n",
      "Converting transcripts: 100%|██████████| 544/544 [00:01<00:00, 304.91it/s]\n"
     ]
    }
   ],
   "source": [
    "from cdp_data import datasets, CDPInstances\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Set randomness\n",
    "np.random.seed(60)\n",
    "\n",
    "for council in [\n",
    "    CDPInstances.Seattle,\n",
    "    CDPInstances.Oakland,\n",
    "    CDPInstances.Richmond,\n",
    "]:\n",
    "    ds = datasets.get_session_dataset(\n",
    "        council,\n",
    "        store_transcript=True,\n",
    "        store_transcript_as_csv=True,\n",
    "        start_datetime=\"2020-01-01\",\n",
    "        end_datetime=\"2024-01-01\",\n",
    "        raise_on_error=False,\n",
    "    )\n",
    "\n",
    "    # overall directory for saving\n",
    "    storage_dir = Path(f\"{council}-transcripts/\")\n",
    "    storage_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    # iter sessions \n",
    "    for _, row in ds.iterrows():\n",
    "        # create the copy path\n",
    "        transcript_copy_path = storage_dir / f\"{row['id']}.csv\"\n",
    "\n",
    "        # read the original transcript\n",
    "        transcript = pd.read_csv(row.transcript_as_csv_path)\n",
    "\n",
    "        # keep only the index and text columns\n",
    "        transcript = transcript[[\n",
    "            \"index\",\n",
    "            \"text\",\n",
    "        ]]\n",
    "\n",
    "        # rename index to sentence_index\n",
    "        transcript = transcript.rename(columns={\"index\": \"sentence_index\"})\n",
    "\n",
    "        # add column for session id\n",
    "        transcript[\"session_id\"] = row[\"id\"]\n",
    "\n",
    "        # add column for council\n",
    "        transcript[\"council\"] = council\n",
    "\n",
    "        # save the modified transcript\n",
    "        transcript.to_csv(transcript_copy_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "We need to convert the annotations into a set of examples ready for training, with context windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 594/674 [00:01<00:00, 532.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row errored: oakland - 363760c5a502\n",
      "[Errno 2] No such file or directory: 'cdp-oakland-ba81c097-transcripts/363760c5a502.csv'\n",
      "Row errored: oakland - 43df4943ac92\n",
      "[Errno 2] No such file or directory: 'cdp-oakland-ba81c097-transcripts/43df4943ac92.csv'\n",
      "Row errored: oakland - cfb96e89ee1d\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "single positional indexer is out-of-bounds\n",
      "Row errored: oakland - 60ec6e138396\n",
      "[Errno 2] No such file or directory: 'cdp-oakland-ba81c097-transcripts/60ec6e138396.csv'\n",
      "Row errored: oakland - 60ec6e138397\n",
      "[Errno 2] No such file or directory: 'cdp-oakland-ba81c097-transcripts/60ec6e138397.csv'\n",
      "Row errored: oakland - 7719f0e0db102\n",
      "[Errno 2] No such file or directory: 'cdp-oakland-ba81c097-transcripts/7719f0e0db102.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 674/674 [00:01<00:00, 519.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>council</th>\n",
       "      <th>session_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>comment_or_hearing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2400</th>\n",
       "      <td>richmond</td>\n",
       "      <td>5a19cf40c561</td>\n",
       "      <td>And it's really causing our pollen rates durin...</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1390</th>\n",
       "      <td>oakland</td>\n",
       "      <td>b66f2a519bc6</td>\n",
       "      <td>Is it Star 7 or Star 9, Star 9. Alright, thank...</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>oakland</td>\n",
       "      <td>c268b4f107d4</td>\n",
       "      <td>Madam city clerk, let 's Apologies, Madam cler...</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2300</th>\n",
       "      <td>richmond</td>\n",
       "      <td>acb20ef0075e</td>\n",
       "      <td>Oh no, he said it was on the side and was goin...</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2208</th>\n",
       "      <td>richmond</td>\n",
       "      <td>d2e53c930621</td>\n",
       "      <td>Okay. Any questions for the architect? Okay, h...</td>\n",
       "      <td>comment-period-start</td>\n",
       "      <td>hearing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>oakland</td>\n",
       "      <td>f9eccc8d1604</td>\n",
       "      <td>It's important within the Disaggregate the dat...</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2102</th>\n",
       "      <td>oakland</td>\n",
       "      <td>8cdba4bbe55e</td>\n",
       "      <td>Second. And that's a motion by Seconded by Gal...</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364</th>\n",
       "      <td>oakland</td>\n",
       "      <td>b41ee128bb4c</td>\n",
       "      <td>So moved. It's been moved by vice safety chair...</td>\n",
       "      <td>comment-period-start</td>\n",
       "      <td>hearing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>oakland</td>\n",
       "      <td>5e4dcb4f6671</td>\n",
       "      <td>On December 21, 2021, by Ewe Nan Mousily pass ...</td>\n",
       "      <td>comment-period-end</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>seattle</td>\n",
       "      <td>60ad4a44eeee</td>\n",
       "      <td>So any policy issues around race, social justi...</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       council    session_id  \\\n",
       "2400  richmond  5a19cf40c561   \n",
       "1390   oakland  b66f2a519bc6   \n",
       "1447   oakland  c268b4f107d4   \n",
       "2300  richmond  acb20ef0075e   \n",
       "2208  richmond  d2e53c930621   \n",
       "1726   oakland  f9eccc8d1604   \n",
       "2102   oakland  8cdba4bbe55e   \n",
       "1364   oakland  b41ee128bb4c   \n",
       "1981   oakland  5e4dcb4f6671   \n",
       "221    seattle  60ad4a44eeee   \n",
       "\n",
       "                                                   text                 label  \\\n",
       "2400  And it's really causing our pollen rates durin...                 other   \n",
       "1390  Is it Star 7 or Star 9, Star 9. Alright, thank...                 other   \n",
       "1447  Madam city clerk, let 's Apologies, Madam cler...                 other   \n",
       "2300  Oh no, he said it was on the side and was goin...                 other   \n",
       "2208  Okay. Any questions for the architect? Okay, h...  comment-period-start   \n",
       "1726  It's important within the Disaggregate the dat...                 other   \n",
       "2102  Second. And that's a motion by Seconded by Gal...                 other   \n",
       "1364  So moved. It's been moved by vice safety chair...  comment-period-start   \n",
       "1981  On December 21, 2021, by Ewe Nan Mousily pass ...    comment-period-end   \n",
       "221   So any policy issues around race, social justi...                 other   \n",
       "\n",
       "     comment_or_hearing  \n",
       "2400              other  \n",
       "1390              other  \n",
       "1447              other  \n",
       "2300              other  \n",
       "2208            hearing  \n",
       "1726              other  \n",
       "2102              other  \n",
       "1364            hearing  \n",
       "1981            comment  \n",
       "221               other  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from cdp_data import CDPInstances\n",
    "from tqdm import tqdm\n",
    "\n",
    "np.random.seed(60)\n",
    "\n",
    "# read all annotations\n",
    "annotation_pds = []\n",
    "for council_short_name, council_infra_slug in {\n",
    "    \"seattle\": CDPInstances.Seattle,\n",
    "    \"oakland\": CDPInstances.Oakland,\n",
    "    \"richmond\": CDPInstances.Richmond,\n",
    "}.items():\n",
    "    annotations = pd.read_csv(f\"training-data/whole-period-seg-{council_short_name}.csv\")\n",
    "\n",
    "    # add council column\n",
    "    annotations[\"council\"] = council_short_name\n",
    "    annotations[\"council_infra_slug\"] = council_infra_slug\n",
    "\n",
    "    annotation_pds.append(annotations)\n",
    "\n",
    "# Combine all annotations\n",
    "annotations = pd.concat(annotation_pds, ignore_index=True)\n",
    "\n",
    "# Convert nans in \"transcript_quality\" to \"good-safe-use\"\n",
    "# Then drop any rows that aren't good-safe-use\n",
    "annotations[\"transcript_quality\"] = annotations[\"transcript_quality\"].fillna(\"good-safe-use\")\n",
    "annotations[\"transcript_quality\"] = annotations[\"transcript_quality\"].replace({\"good-safe-to-use\": \"good-safe-use\"})\n",
    "annotations = annotations[annotations[\"transcript_quality\"] == \"good-safe-use\"]\n",
    "\n",
    "# Convert -1 in period_start_sentence_index and period_end_sentence_index to nan\n",
    "annotations[\"period_start_sentence_index\"] = annotations[\"period_start_sentence_index\"].replace(-1, np.nan)\n",
    "\n",
    "# Convert nans in \"comment_or_hearing\" to \"comment\"\n",
    "annotations[\"comment_or_hearing\"] = annotations[\"comment_or_hearing\"].fillna(\"comment\")\n",
    "\n",
    "# Keep only the columns we need\n",
    "annotations = annotations[[\n",
    "    \"council\",\n",
    "    \"council_infra_slug\",\n",
    "    \"session_id\",\n",
    "    \"period_start_sentence_index\",\n",
    "    \"period_end_sentence_index\",\n",
    "    \"comment_or_hearing\",\n",
    "]]\n",
    "\n",
    "# Drop any sessions with nan session_id\n",
    "annotations = annotations.dropna(subset=[\"session_id\"])\n",
    "\n",
    "# Ensure that all session_ids are strings\n",
    "annotations[\"session_id\"] = annotations[\"session_id\"].astype(str)\n",
    "\n",
    "# we will always take N random negative samples from the same session\n",
    "n_random_samples = 2\n",
    "\n",
    "# Create context window sets\n",
    "# single sentence means the context window is 1 (only the sentence itself)\n",
    "# three sentence means the context window is 3 (1 before and 1 after)\n",
    "# five sentence means the context window is 5 (2 before and 2 after)\n",
    "single_sentence_examples = []\n",
    "three_sentence_examples = []\n",
    "five_sentence_examples = []\n",
    "\n",
    "def get_context_windows(transcript, center_index) -> tuple[str, str, str]:\n",
    "    # calculate offsets for the three and five sentence examples\n",
    "    # if the offset would go negative, we just use 0 or len(transcript)\n",
    "    three_sentence_start_index = max(center_index - 1, 0)\n",
    "    three_sentence_end_index = min(center_index + 2, len(transcript) - 1)\n",
    "    five_sentence_start_index = max(center_index - 2, 0)\n",
    "    five_sentence_end_index = min(center_index + 3, len(transcript) - 1)\n",
    "\n",
    "    # process the single sentence example\n",
    "    single_sentence = transcript.iloc[center_index][\"text\"].strip()\n",
    "\n",
    "    # process the three sentence example\n",
    "    three_sentence = \" \".join(\n",
    "        transcript.iloc[\n",
    "            three_sentence_start_index:\n",
    "            three_sentence_end_index\n",
    "        ][\"text\"]\n",
    "    ).strip()\n",
    "\n",
    "    # process the five sentence example\n",
    "    five_sentence = \" \".join(\n",
    "        transcript.iloc[\n",
    "            five_sentence_start_index:\n",
    "            five_sentence_end_index\n",
    "        ][\"text\"]\n",
    "    ).strip()\n",
    "\n",
    "    return single_sentence, three_sentence, five_sentence\n",
    "\n",
    "\n",
    "# iterate over the rows of the annotations and create the context window sets\n",
    "for _, row in tqdm(annotations.iterrows(), total=len(annotations)):\n",
    "    try:\n",
    "        # load the session transcript csv\n",
    "        transcript = pd.read_csv(f\"{row.council_infra_slug}-transcripts/{row.session_id.strip()}.csv\")\n",
    "\n",
    "        # Convert rows with text as NaN to empty string\n",
    "        transcript[\"text\"] = transcript[\"text\"].fillna(\"\")\n",
    "\n",
    "        # if we have a start sentence index, add all of the context windows samples\n",
    "        if not np.isnan(row.period_start_sentence_index):\n",
    "            # get the start sentence index\n",
    "            period_start_sentence_index = int(row.period_start_sentence_index)\n",
    "\n",
    "            # get the context windows\n",
    "            single_sentence, three_sentence, five_sentence = get_context_windows(\n",
    "                transcript,\n",
    "                period_start_sentence_index,\n",
    "            )\n",
    "\n",
    "            # add all as examples\n",
    "            single_sentence_examples.append({\n",
    "                \"council\": row.council,\n",
    "                \"session_id\": row.session_id,\n",
    "                \"text\": single_sentence,\n",
    "                \"label\": \"comment-period-start\",\n",
    "                \"comment_or_hearing\": row.comment_or_hearing,\n",
    "            })\n",
    "            three_sentence_examples.append({\n",
    "                \"council\": row.council,\n",
    "                \"session_id\": row.session_id,\n",
    "                \"text\": three_sentence,\n",
    "                \"label\": \"comment-period-start\",\n",
    "                \"comment_or_hearing\": row.comment_or_hearing,\n",
    "            })\n",
    "            five_sentence_examples.append({\n",
    "                \"council\": row.council,\n",
    "                \"session_id\": row.session_id,\n",
    "                \"text\": five_sentence,\n",
    "                \"label\": \"comment-period-start\",\n",
    "                \"comment_or_hearing\": row.comment_or_hearing,\n",
    "            })\n",
    "\n",
    "        # if we have a end sentence index, add all of the context windows samples\n",
    "        if not np.isnan(row.period_end_sentence_index):\n",
    "            # get the end sentence index\n",
    "            period_end_sentence_index = int(row.period_end_sentence_index)\n",
    "\n",
    "            # get the context windows\n",
    "            single_sentence, three_sentence, five_sentence = get_context_windows(\n",
    "                transcript,\n",
    "                period_end_sentence_index,\n",
    "            )\n",
    "\n",
    "            # add all as examples\n",
    "            single_sentence_examples.append({\n",
    "                \"council\": row.council,\n",
    "                \"session_id\": row.session_id,\n",
    "                \"text\": single_sentence,\n",
    "                \"label\": \"comment-period-end\",\n",
    "                \"comment_or_hearing\": row.comment_or_hearing,\n",
    "            })\n",
    "            three_sentence_examples.append({\n",
    "                \"council\": row.council,\n",
    "                \"session_id\": row.session_id,\n",
    "                \"text\": three_sentence,\n",
    "                \"label\": \"comment-period-end\",\n",
    "                \"comment_or_hearing\": row.comment_or_hearing,\n",
    "            })\n",
    "            five_sentence_examples.append({\n",
    "                \"council\": row.council,\n",
    "                \"session_id\": row.session_id,\n",
    "                \"text\": five_sentence,\n",
    "                \"label\": \"comment-period-end\",\n",
    "                \"comment_or_hearing\": row.comment_or_hearing,\n",
    "            })\n",
    "        \n",
    "        # choose N random negative samples from the same session\n",
    "        # we start by finding N random negative sentence indicies to use as\n",
    "        # the center of the context windows\n",
    "        # make sure we specifically exclude the start and end sentence indices\n",
    "        block_length = 5\n",
    "        valid_indices = list(range(len(transcript)))\n",
    "        if not np.isnan(row.period_start_sentence_index):\n",
    "            # remove the period start sentence index, and the block length before and after\n",
    "            valid_indices = list(\n",
    "                set(valid_indices) - set(\n",
    "                    range(\n",
    "                        int(row.period_start_sentence_index) - block_length,\n",
    "                        int(row.period_start_sentence_index) + block_length + 1,\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        if not np.isnan(row.period_end_sentence_index):\n",
    "            # remove the period end sentence index, and the block length before and after\n",
    "            valid_indices = list(\n",
    "                set(valid_indices) - set(\n",
    "                    range(\n",
    "                        int(row.period_end_sentence_index) - block_length,\n",
    "                        int(row.period_end_sentence_index) + block_length + 1,\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        # choose N random negative samples\n",
    "        negative_samples = np.random.choice(valid_indices, n_random_samples, replace=False)\n",
    "\n",
    "        # process the negative samples\n",
    "        for negative_sample in negative_samples:\n",
    "            # get the context windows\n",
    "            single_sentence, three_sentence, five_sentence = get_context_windows(\n",
    "                transcript,\n",
    "                negative_sample,\n",
    "            )\n",
    "\n",
    "            # add all as examples\n",
    "            single_sentence_examples.append({\n",
    "                \"council\": row.council,\n",
    "                \"session_id\": row.session_id,\n",
    "                \"text\": single_sentence,\n",
    "                \"label\": \"other\",\n",
    "                \"comment_or_hearing\": \"other\",\n",
    "            })\n",
    "            three_sentence_examples.append({\n",
    "                \"council\": row.council,\n",
    "                \"session_id\": row.session_id,\n",
    "                \"text\": three_sentence,\n",
    "                \"label\": \"other\",\n",
    "                \"comment_or_hearing\": \"other\",\n",
    "            })\n",
    "            five_sentence_examples.append({\n",
    "                \"council\": row.council,\n",
    "                \"session_id\": row.session_id,\n",
    "                \"text\": five_sentence,\n",
    "                \"label\": \"other\",\n",
    "                \"comment_or_hearing\": \"other\",\n",
    "            })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Row errored: {row.council} - {row.session_id}\")\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "# create the dataframes\n",
    "single_sentence_examples = pd.DataFrame(single_sentence_examples)\n",
    "three_sentence_examples = pd.DataFrame(three_sentence_examples)\n",
    "five_sentence_examples = pd.DataFrame(five_sentence_examples)\n",
    "\n",
    "# save the dataframes\n",
    "single_sentence_examples.to_csv(\"training-data/whole-comment-seg-single-sentence-examples.csv\", index=False)\n",
    "three_sentence_examples.to_csv(\"training-data/whole-comment-seg-three-sentence-examples.csv\", index=False)\n",
    "five_sentence_examples.to_csv(\"training-data/whole-comment-seg-five-sentence-examples.csv\", index=False)\n",
    "\n",
    "three_sentence_examples.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other                   1336\n",
       "comment-period-end       613\n",
       "comment-period-start     599\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_sentence_examples.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "oakland     1464\n",
       "seattle      688\n",
       "richmond     396\n",
       "Name: council, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_sentence_examples.council.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "city-council",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
