{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Whole Comment Seg Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to create a copy of the transcripts in this directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evamaxfield/micromamba/envs/city-council/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching each model attached to event_ref: 100%|██████████| 640/640 [00:03<00:00, 161.30it/s]\n",
      "Fetching transcripts: 100%|██████████| 640/640 [00:08<00:00, 77.10it/s]\n",
      "Converting transcripts: 100%|██████████| 640/640 [00:01<00:00, 389.23it/s]\n",
      "Fetching each model attached to event_ref: 100%|██████████| 308/308 [00:03<00:00, 88.02it/s] \n",
      "Fetching transcripts: 100%|██████████| 308/308 [00:03<00:00, 78.17it/s]\n",
      "Converting transcripts: 100%|██████████| 307/307 [00:01<00:00, 196.14it/s]\n",
      "Fetching each model attached to event_ref: 100%|██████████| 544/544 [00:06<00:00, 89.91it/s] \n",
      "Fetching transcripts: 100%|██████████| 544/544 [00:08<00:00, 62.48it/s]\n",
      "Converting transcripts: 100%|██████████| 544/544 [00:01<00:00, 347.64it/s]\n"
     ]
    }
   ],
   "source": [
    "from cdp_data import datasets, CDPInstances\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Set randomness\n",
    "np.random.seed(60)\n",
    "\n",
    "for council in [\n",
    "    CDPInstances.Seattle,\n",
    "    CDPInstances.Oakland,\n",
    "    CDPInstances.Richmond,\n",
    "]:\n",
    "    ds = datasets.get_session_dataset(\n",
    "        council,\n",
    "        store_transcript=True,\n",
    "        store_transcript_as_csv=True,\n",
    "        start_datetime=\"2020-01-01\",\n",
    "        end_datetime=\"2024-01-01\",\n",
    "        raise_on_error=False,\n",
    "    )\n",
    "\n",
    "    # overall directory for saving\n",
    "    storage_dir = Path(f\"{council}-transcripts/\")\n",
    "    storage_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    # iter sessions \n",
    "    for _, row in ds.iterrows():\n",
    "        # create the copy path\n",
    "        transcript_copy_path = storage_dir / f\"{row['id']}.csv\"\n",
    "\n",
    "        # read the original transcript\n",
    "        transcript = pd.read_csv(row.transcript_as_csv_path)\n",
    "\n",
    "        # keep only the index and text columns\n",
    "        transcript = transcript[[\n",
    "            \"index\",\n",
    "            \"text\",\n",
    "        ]]\n",
    "\n",
    "        # rename index to sentence_index\n",
    "        transcript = transcript.rename(columns={\"index\": \"sentence_index\"})\n",
    "\n",
    "        # add column for session id\n",
    "        transcript[\"session_id\"] = row[\"id\"]\n",
    "\n",
    "        # add column for council\n",
    "        transcript[\"council\"] = council\n",
    "\n",
    "        # save the modified transcript\n",
    "        transcript.to_csv(transcript_copy_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "We need to convert the annotations into a set of examples ready for training, with context windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 571/694 [00:01<00:00, 514.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row errored: oakland - 363760c5a502\n",
      "[Errno 2] No such file or directory: 'cdp-oakland-ba81c097-transcripts/363760c5a502.csv'\n",
      "Row errored: oakland - 43df4943ac92\n",
      "[Errno 2] No such file or directory: 'cdp-oakland-ba81c097-transcripts/43df4943ac92.csv'\n",
      "Row errored: oakland - cfb96e89ee1d\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "single positional indexer is out-of-bounds\n",
      "Row errored: oakland - 60ec6e138396\n",
      "[Errno 2] No such file or directory: 'cdp-oakland-ba81c097-transcripts/60ec6e138396.csv'\n",
      "Row errored: oakland - 60ec6e138397\n",
      "[Errno 2] No such file or directory: 'cdp-oakland-ba81c097-transcripts/60ec6e138397.csv'\n",
      "Row errored: oakland - 7719f0e0db102\n",
      "[Errno 2] No such file or directory: 'cdp-oakland-ba81c097-transcripts/7719f0e0db102.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 694/694 [00:01<00:00, 504.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>council</th>\n",
       "      <th>session_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>comment_or_hearing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>oakland</td>\n",
       "      <td>c1762edb4651</td>\n",
       "      <td>In our Mid-Cycle budget in June, I did add to ...</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2147</th>\n",
       "      <td>oakland</td>\n",
       "      <td>8fc230ade8f7</td>\n",
       "      <td>Madam city clerk? Through the chair to the cit...</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2522</th>\n",
       "      <td>richmond</td>\n",
       "      <td>4740e71a6966</td>\n",
       "      <td>Public hearing. The committee will now hold a ...</td>\n",
       "      <td>comment-period-start</td>\n",
       "      <td>hearing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>oakland</td>\n",
       "      <td>6e8e3394a044</td>\n",
       "      <td>Oh, the CEO of Unity Council. I'm not surprise...</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157</th>\n",
       "      <td>oakland</td>\n",
       "      <td>6fb6a975adeb</td>\n",
       "      <td>I do apologize, your two Thank you to all the ...</td>\n",
       "      <td>comment-period-end</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>oakland</td>\n",
       "      <td>6fc22799cf42</td>\n",
       "      <td>And then, as if you can stop sharing your scre...</td>\n",
       "      <td>comment-period-start</td>\n",
       "      <td>hearing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>seattle</td>\n",
       "      <td>730ba0763750</td>\n",
       "      <td>Thank you very much. That was our final speake...</td>\n",
       "      <td>comment-period-end</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>seattle</td>\n",
       "      <td>2315e3a68f6e</td>\n",
       "      <td>Okay. Okay. Okay.</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2478</th>\n",
       "      <td>richmond</td>\n",
       "      <td>5a19cf40c561</td>\n",
       "      <td>So let's do that. It's open for public comment...</td>\n",
       "      <td>comment-period-start</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2380</th>\n",
       "      <td>richmond</td>\n",
       "      <td>acb20ef0075e</td>\n",
       "      <td>Do I hear a motion? Mr. Wheeler is so moved. A...</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       council    session_id  \\\n",
       "1478   oakland  c1762edb4651   \n",
       "2147   oakland  8fc230ade8f7   \n",
       "2522  richmond  4740e71a6966   \n",
       "1123   oakland  6e8e3394a044   \n",
       "1157   oakland  6fb6a975adeb   \n",
       "1168   oakland  6fc22799cf42   \n",
       "295    seattle  730ba0763750   \n",
       "326    seattle  2315e3a68f6e   \n",
       "2478  richmond  5a19cf40c561   \n",
       "2380  richmond  acb20ef0075e   \n",
       "\n",
       "                                                   text                 label  \\\n",
       "1478  In our Mid-Cycle budget in June, I did add to ...                 other   \n",
       "2147  Madam city clerk? Through the chair to the cit...                 other   \n",
       "2522  Public hearing. The committee will now hold a ...  comment-period-start   \n",
       "1123  Oh, the CEO of Unity Council. I'm not surprise...                 other   \n",
       "1157  I do apologize, your two Thank you to all the ...    comment-period-end   \n",
       "1168  And then, as if you can stop sharing your scre...  comment-period-start   \n",
       "295   Thank you very much. That was our final speake...    comment-period-end   \n",
       "326                                   Okay. Okay. Okay.                 other   \n",
       "2478  So let's do that. It's open for public comment...  comment-period-start   \n",
       "2380  Do I hear a motion? Mr. Wheeler is so moved. A...                 other   \n",
       "\n",
       "     comment_or_hearing  \n",
       "1478              other  \n",
       "2147              other  \n",
       "2522            hearing  \n",
       "1123              other  \n",
       "1157            comment  \n",
       "1168            hearing  \n",
       "295             comment  \n",
       "326               other  \n",
       "2478            comment  \n",
       "2380              other  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from cdp_data import CDPInstances\n",
    "from tqdm import tqdm\n",
    "\n",
    "np.random.seed(60)\n",
    "\n",
    "# read all annotations\n",
    "annotation_pds = []\n",
    "for council_short_name, council_infra_slug in {\n",
    "    \"seattle\": CDPInstances.Seattle,\n",
    "    \"oakland\": CDPInstances.Oakland,\n",
    "    \"richmond\": CDPInstances.Richmond,\n",
    "}.items():\n",
    "    annotations = pd.read_csv(f\"training-data/whole-period-seg-{council_short_name}.csv\")\n",
    "\n",
    "    # add council column\n",
    "    annotations[\"council\"] = council_short_name\n",
    "    annotations[\"council_infra_slug\"] = council_infra_slug\n",
    "\n",
    "    annotation_pds.append(annotations)\n",
    "\n",
    "# Combine all annotations\n",
    "annotations = pd.concat(annotation_pds, ignore_index=True)\n",
    "\n",
    "# Convert nans in \"transcript_quality\" to \"good-safe-use\"\n",
    "# Then drop any rows that aren't good-safe-use\n",
    "annotations[\"transcript_quality\"] = annotations[\"transcript_quality\"].fillna(\"good-safe-use\")\n",
    "annotations[\"transcript_quality\"] = annotations[\"transcript_quality\"].replace({\"good-safe-to-use\": \"good-safe-use\"})\n",
    "annotations = annotations[annotations[\"transcript_quality\"] == \"good-safe-use\"]\n",
    "\n",
    "# Convert -1 in period_start_sentence_index and period_end_sentence_index to nan\n",
    "annotations[\"period_start_sentence_index\"] = annotations[\"period_start_sentence_index\"].replace(-1, np.nan)\n",
    "\n",
    "# Convert nans in \"comment_or_hearing\" to \"comment\"\n",
    "annotations[\"comment_or_hearing\"] = annotations[\"comment_or_hearing\"].fillna(\"comment\")\n",
    "\n",
    "# Keep only the columns we need\n",
    "annotations = annotations[[\n",
    "    \"council\",\n",
    "    \"council_infra_slug\",\n",
    "    \"session_id\",\n",
    "    \"period_start_sentence_index\",\n",
    "    \"period_end_sentence_index\",\n",
    "    \"comment_or_hearing\",\n",
    "]]\n",
    "\n",
    "# Drop any sessions with nan session_id\n",
    "annotations = annotations.dropna(subset=[\"session_id\"])\n",
    "\n",
    "# Ensure that all session_ids are strings\n",
    "annotations[\"session_id\"] = annotations[\"session_id\"].astype(str)\n",
    "\n",
    "# we will always take N random negative samples from the same session\n",
    "n_random_samples = 2\n",
    "\n",
    "# Create context window sets\n",
    "# single sentence means the context window is 1 (only the sentence itself)\n",
    "# three sentence means the context window is 3 (1 before and 1 after)\n",
    "# five sentence means the context window is 5 (2 before and 2 after)\n",
    "single_sentence_examples = []\n",
    "three_sentence_examples = []\n",
    "five_sentence_examples = []\n",
    "\n",
    "def get_context_windows(transcript, center_index) -> tuple[str, str, str]:\n",
    "    # calculate offsets for the three and five sentence examples\n",
    "    # if the offset would go negative, we just use 0 or len(transcript)\n",
    "    three_sentence_start_index = max(center_index - 1, 0)\n",
    "    three_sentence_end_index = min(center_index + 2, len(transcript) - 1)\n",
    "    five_sentence_start_index = max(center_index - 2, 0)\n",
    "    five_sentence_end_index = min(center_index + 3, len(transcript) - 1)\n",
    "\n",
    "    # process the single sentence example\n",
    "    single_sentence = transcript.iloc[center_index][\"text\"].strip()\n",
    "\n",
    "    # process the three sentence example\n",
    "    three_sentence = \" \".join(\n",
    "        transcript.iloc[\n",
    "            three_sentence_start_index:\n",
    "            three_sentence_end_index\n",
    "        ][\"text\"]\n",
    "    ).strip()\n",
    "\n",
    "    # process the five sentence example\n",
    "    five_sentence = \" \".join(\n",
    "        transcript.iloc[\n",
    "            five_sentence_start_index:\n",
    "            five_sentence_end_index\n",
    "        ][\"text\"]\n",
    "    ).strip()\n",
    "\n",
    "    return single_sentence, three_sentence, five_sentence\n",
    "\n",
    "\n",
    "# iterate over the rows of the annotations and create the context window sets\n",
    "for _, row in tqdm(annotations.iterrows(), total=len(annotations)):\n",
    "    try:\n",
    "        # load the session transcript csv\n",
    "        transcript = pd.read_csv(f\"{row.council_infra_slug}-transcripts/{row.session_id.strip()}.csv\")\n",
    "\n",
    "        # Convert rows with text as NaN to empty string\n",
    "        transcript[\"text\"] = transcript[\"text\"].fillna(\"\")\n",
    "\n",
    "        # if we have a start sentence index, add all of the context windows samples\n",
    "        if not np.isnan(row.period_start_sentence_index):\n",
    "            # get the start sentence index\n",
    "            period_start_sentence_index = int(row.period_start_sentence_index)\n",
    "\n",
    "            # get the context windows\n",
    "            single_sentence, three_sentence, five_sentence = get_context_windows(\n",
    "                transcript,\n",
    "                period_start_sentence_index,\n",
    "            )\n",
    "\n",
    "            # add all as examples\n",
    "            single_sentence_examples.append({\n",
    "                \"council\": row.council,\n",
    "                \"session_id\": row.session_id,\n",
    "                \"text\": single_sentence,\n",
    "                \"label\": \"comment-period-start\",\n",
    "                \"comment_or_hearing\": row.comment_or_hearing,\n",
    "            })\n",
    "            three_sentence_examples.append({\n",
    "                \"council\": row.council,\n",
    "                \"session_id\": row.session_id,\n",
    "                \"text\": three_sentence,\n",
    "                \"label\": \"comment-period-start\",\n",
    "                \"comment_or_hearing\": row.comment_or_hearing,\n",
    "            })\n",
    "            five_sentence_examples.append({\n",
    "                \"council\": row.council,\n",
    "                \"session_id\": row.session_id,\n",
    "                \"text\": five_sentence,\n",
    "                \"label\": \"comment-period-start\",\n",
    "                \"comment_or_hearing\": row.comment_or_hearing,\n",
    "            })\n",
    "\n",
    "        # if we have a end sentence index, add all of the context windows samples\n",
    "        if not np.isnan(row.period_end_sentence_index):\n",
    "            # get the end sentence index\n",
    "            period_end_sentence_index = int(row.period_end_sentence_index)\n",
    "\n",
    "            # get the context windows\n",
    "            single_sentence, three_sentence, five_sentence = get_context_windows(\n",
    "                transcript,\n",
    "                period_end_sentence_index,\n",
    "            )\n",
    "\n",
    "            # add all as examples\n",
    "            single_sentence_examples.append({\n",
    "                \"council\": row.council,\n",
    "                \"session_id\": row.session_id,\n",
    "                \"text\": single_sentence,\n",
    "                \"label\": \"comment-period-end\",\n",
    "                \"comment_or_hearing\": row.comment_or_hearing,\n",
    "            })\n",
    "            three_sentence_examples.append({\n",
    "                \"council\": row.council,\n",
    "                \"session_id\": row.session_id,\n",
    "                \"text\": three_sentence,\n",
    "                \"label\": \"comment-period-end\",\n",
    "                \"comment_or_hearing\": row.comment_or_hearing,\n",
    "            })\n",
    "            five_sentence_examples.append({\n",
    "                \"council\": row.council,\n",
    "                \"session_id\": row.session_id,\n",
    "                \"text\": five_sentence,\n",
    "                \"label\": \"comment-period-end\",\n",
    "                \"comment_or_hearing\": row.comment_or_hearing,\n",
    "            })\n",
    "        \n",
    "        # choose N random negative samples from the same session\n",
    "        # we start by finding N random negative sentence indicies to use as\n",
    "        # the center of the context windows\n",
    "        # make sure we specifically exclude the start and end sentence indices\n",
    "        block_length = 5\n",
    "        valid_indices = list(range(len(transcript)))\n",
    "        if not np.isnan(row.period_start_sentence_index):\n",
    "            # remove the period start sentence index, and the block length before and after\n",
    "            valid_indices = list(\n",
    "                set(valid_indices) - set(\n",
    "                    range(\n",
    "                        int(row.period_start_sentence_index) - block_length,\n",
    "                        int(row.period_start_sentence_index) + block_length + 1,\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        if not np.isnan(row.period_end_sentence_index):\n",
    "            # remove the period end sentence index, and the block length before and after\n",
    "            valid_indices = list(\n",
    "                set(valid_indices) - set(\n",
    "                    range(\n",
    "                        int(row.period_end_sentence_index) - block_length,\n",
    "                        int(row.period_end_sentence_index) + block_length + 1,\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        # choose N random negative samples\n",
    "        negative_samples = np.random.choice(valid_indices, n_random_samples, replace=False)\n",
    "\n",
    "        # process the negative samples\n",
    "        for negative_sample in negative_samples:\n",
    "            # get the context windows\n",
    "            single_sentence, three_sentence, five_sentence = get_context_windows(\n",
    "                transcript,\n",
    "                negative_sample,\n",
    "            )\n",
    "\n",
    "            # add all as examples\n",
    "            single_sentence_examples.append({\n",
    "                \"council\": row.council,\n",
    "                \"session_id\": row.session_id,\n",
    "                \"text\": single_sentence,\n",
    "                \"label\": \"other\",\n",
    "                \"comment_or_hearing\": \"other\",\n",
    "            })\n",
    "            three_sentence_examples.append({\n",
    "                \"council\": row.council,\n",
    "                \"session_id\": row.session_id,\n",
    "                \"text\": three_sentence,\n",
    "                \"label\": \"other\",\n",
    "                \"comment_or_hearing\": \"other\",\n",
    "            })\n",
    "            five_sentence_examples.append({\n",
    "                \"council\": row.council,\n",
    "                \"session_id\": row.session_id,\n",
    "                \"text\": five_sentence,\n",
    "                \"label\": \"other\",\n",
    "                \"comment_or_hearing\": \"other\",\n",
    "            })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Row errored: {row.council} - {row.session_id}\")\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "# create the dataframes\n",
    "single_sentence_examples = pd.DataFrame(single_sentence_examples)\n",
    "three_sentence_examples = pd.DataFrame(three_sentence_examples)\n",
    "five_sentence_examples = pd.DataFrame(five_sentence_examples)\n",
    "\n",
    "# save the dataframes\n",
    "single_sentence_examples.to_csv(\"training-data/whole-comment-seg-single-sentence-examples.csv\", index=False)\n",
    "three_sentence_examples.to_csv(\"training-data/whole-comment-seg-three-sentence-examples.csv\", index=False)\n",
    "five_sentence_examples.to_csv(\"training-data/whole-comment-seg-five-sentence-examples.csv\", index=False)\n",
    "\n",
    "three_sentence_examples.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other                   1376\n",
       "comment-period-end       633\n",
       "comment-period-start     619\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_sentence_examples.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "oakland     1544\n",
       "seattle      688\n",
       "richmond     396\n",
       "Name: council, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_sentence_examples.council.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "city-council",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
